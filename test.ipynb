{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred (EntityAlreadyExists) when calling the CreateRole operation: Role with name dwhRole already exists.\n",
      "An error occurred (ClusterAlreadyExists) when calling the CreateCluster operation: Cluster already exists\n",
      "                 Key  \\\n",
      "0  ClusterIdentifier   \n",
      "1  NodeType            \n",
      "2  ClusterStatus       \n",
      "3  MasterUsername      \n",
      "4  DBName              \n",
      "5  Endpoint            \n",
      "6  VpcId               \n",
      "7  NumberOfNodes       \n",
      "\n",
      "                                                                                   Value  \n",
      "0  dwhcluster                                                                             \n",
      "1  dc2.large                                                                              \n",
      "2  available                                                                              \n",
      "3  iandwh                                                                                 \n",
      "4  redshiftdwhdb                                                                          \n",
      "5  {'Address': 'dwhcluster.cbcdtjq67k0w.us-west-2.redshift.amazonaws.com', 'Port': 5439}  \n",
      "6  vpc-c6d1afbe                                                                           \n",
      "7  4                                                                                      \n",
      "DWH_ENDPOINT ::  dwhcluster.cbcdtjq67k0w.us-west-2.redshift.amazonaws.com\n",
      "DWH_ROLE_ARN ::  arn:aws:iam::186402456289:role/dwhRole\n",
      "vpc-c6d1afbe\n",
      "ec2.SecurityGroup(id='sg-f32738a4')\n",
      "An error occurred (InvalidPermission.Duplicate) when calling the AuthorizeSecurityGroupIngress operation: the specified rule \"peer: 0.0.0.0/0, TCP, from port: 5439, to port: 5439, ALLOW\" already exists\n"
     ]
    }
   ],
   "source": [
    "%run aws_dwh.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop\n",
      "DROP TABLE IF EXISTS staging_events\n",
      "drop\n",
      "DROP TABLE IF EXISTS staging_songs\n",
      "drop\n",
      "DROP TABLE IF EXISTS fact_songplay\n",
      "drop\n",
      "DROP TABLE IF EXISTS dim_user\n",
      "drop\n",
      "DROP TABLE IF EXISTS dim_song\n",
      "drop\n",
      "DROP TABLE IF EXISTS dim_artist\n",
      "drop\n",
      "DROP TABLE IF EXISTS dim_time\n",
      "\n",
      "CREATE TABLE IF NOT EXISTS staging_events\n",
      "(\n",
      "artist          VARCHAR,\n",
      "auth            VARCHAR, \n",
      "firstName       VARCHAR,\n",
      "gender          VARCHAR,   \n",
      "itemInSession   INTEGER,\n",
      "lastName        VARCHAR,\n",
      "length          FLOAT,\n",
      "level           VARCHAR, \n",
      "location        VARCHAR,\n",
      "method          VARCHAR,\n",
      "page            VARCHAR,\n",
      "registration    BIGINT,\n",
      "sessionId       INTEGER,\n",
      "song            VARCHAR,\n",
      "status          INTEGER,\n",
      "ts              TIMESTAMP,\n",
      "userAgent       VARCHAR,\n",
      "userId          INTEGER\n",
      ");\n",
      "\n",
      "\n",
      "CREATE TABLE IF NOT EXISTS staging_songs\n",
      "(\n",
      "song_id            VARCHAR,\n",
      "num_songs          INTEGER,\n",
      "title              VARCHAR,\n",
      "artist_name        VARCHAR,\n",
      "artist_latitude    FLOAT,\n",
      "year               INTEGER,\n",
      "duration           FLOAT,\n",
      "artist_id          VARCHAR,\n",
      "artist_longitude   FLOAT,\n",
      "artist_location    VARCHAR\n",
      ");\n",
      "\n",
      "\n",
      "CREATE TABLE IF NOT EXISTS fact_songplay\n",
      "(\n",
      "songplay_id          INTEGER IDENTITY(0,1) PRIMARY KEY sortkey,\n",
      "start_time           TIMESTAMP NOT NULL,\n",
      "user_id              INTEGER NOT NULL,\n",
      "level                VARCHAR,\n",
      "song_id              VARCHAR NOT NULL,\n",
      "artist_id            VARCHAR NOT NULL,\n",
      "session_id           INTEGER,\n",
      "location             VARCHAR,\n",
      "user_agent           VARCHAR\n",
      ");\n",
      "\n",
      "\n",
      "CREATE TABLE IF NOT EXISTS dim_user\n",
      "(\n",
      "user_id INTEGER PRIMARY KEY distkey,\n",
      "first_name      VARCHAR,\n",
      "last_name       VARCHAR,\n",
      "gender          VARCHAR,\n",
      "level           VARCHAR\n",
      ");\n",
      "\n",
      "\n",
      "CREATE TABLE IF NOT EXISTS dim_song\n",
      "(\n",
      "song_id     VARCHAR PRIMARY KEY,\n",
      "title       VARCHAR,\n",
      "artist_id   VARCHAR distkey,\n",
      "year        INTEGER,\n",
      "duration    FLOAT\n",
      ");\n",
      "\n",
      "\n",
      "CREATE TABLE IF NOT EXISTS dim_artist\n",
      "(\n",
      "artist_id          VARCHAR PRIMARY KEY distkey,\n",
      "name               VARCHAR,\n",
      "location           VARCHAR,\n",
      "latitude           FLOAT,\n",
      "longitude          FLOAT\n",
      ");\n",
      "\n",
      "\n",
      "CREATE TABLE IF NOT EXISTS dim_time\n",
      "(\n",
      "start_time    TIMESTAMP PRIMARY KEY sortkey distkey,\n",
      "hour          INTEGER,\n",
      "day           INTEGER,\n",
      "week          INTEGER,\n",
      "month         INTEGER,\n",
      "year          INTEGER,\n",
      "weekday       INTEGER\n",
      ");\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run create_tables.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing query \n",
      "COPY staging_events FROM 's3://udacity-dend/log_data'\n",
      "    iam_role  'arn:aws:iam::186402456289:role/dwhRole'\n",
      "    COMPUPDATE OFF region 'us-west-2'\n",
      "    TIMEFORMAT as 'epochmillisecs'\n",
      "    TRUNCATECOLUMNS BLANKSASNULL EMPTYASNULL\n",
      "    FORMAT AS JSON 's3://udacity-dend/log_json_path.json';\n",
      "\n",
      "executed query.\n",
      "executing query \n",
      "COPY staging_songs FROM 's3://udacity-dend/song_data'\n",
      "    iam_role  'arn:aws:iam::186402456289:role/dwhRole'\n",
      "    COMPUPDATE OFF region 'us-west-2'\n",
      "    FORMAT AS JSON 'auto' \n",
      "    TRUNCATECOLUMNS BLANKSASNULL EMPTYASNULL;\n",
      "\n",
      "executed query.\n",
      "executing query \n",
      "INSERT INTO fact_songplay(start_time, user_id, level, song_id, artist_id, session_id, location, user_agent)\n",
      "SELECT DISTINCT to_timestamp(to_char(se.ts, '9999-99-99 99:99:99'),'YYYY-MM-DD HH24:MI:SS'),\n",
      "                se.userId as user_id,\n",
      "                se.level as level,\n",
      "                ss.song_id as song_id,\n",
      "                ss.artist_id as artist_id,\n",
      "                se.sessionId as session_id,\n",
      "                se.location as location,\n",
      "                se.userAgent as user_agent\n",
      "FROM staging_events se\n",
      "JOIN staging_songs ss ON se.song = ss.title AND se.artist = ss.artist_name\n",
      "WHERE se.page='NextSong';\n",
      "\n",
      "executed query.\n",
      "executing query \n",
      "INSERT INTO dim_user(user_id, first_name, last_name, gender, level)\n",
      "SELECT DISTINCT userId as user_id,\n",
      "                firstName as first_name,\n",
      "                lastName as last_name,\n",
      "                gender as gender,\n",
      "                level as level\n",
      "FROM staging_events\n",
      "where userId IS NOT NULL and page='NextSong';\n",
      "\n",
      "executed query.\n",
      "executing query \n",
      "INSERT INTO dim_song(song_id, title, artist_id, year, duration)\n",
      "SELECT DISTINCT song_id as song_id,\n",
      "                title as title,\n",
      "                artist_id as artist_id,\n",
      "                year as year,\n",
      "                duration as duration\n",
      "FROM staging_songs\n",
      "WHERE song_id IS NOT NULL;\n",
      "\n",
      "executed query.\n",
      "executing query \n",
      "INSERT INTO dim_artist(artist_id, name, location, latitude, longitude)\n",
      "SELECT DISTINCT artist_id as artist_id,\n",
      "                artist_name as name,\n",
      "                artist_location as location,\n",
      "                artist_latitude as latitude,\n",
      "                artist_longitude as longitude\n",
      "FROM staging_songs\n",
      "where artist_id IS NOT NULL;\n",
      "\n",
      "executed query.\n",
      "executing query INSERT INTO dim_time(start_time, hour, day, week, month, year, weekday)\n",
      "SELECT distinct ts,\n",
      "                EXTRACT(hour from ts),\n",
      "                EXTRACT(day from ts),\n",
      "                EXTRACT(week from ts),\n",
      "                EXTRACT(month from ts),\n",
      "                EXTRACT(year from ts),\n",
      "                EXTRACT(weekday from ts)\n",
      "FROM staging_events\n",
      "WHERE ts IS NOT NULL;\n",
      "\n",
      "executed query.\n"
     ]
    }
   ],
   "source": [
    "%run etl.py "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
